{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import pickle\n",
    "import socket\n",
    "import base64\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_COUNTS = 3\n",
    "TIME_SLEEP = 1\n",
    "DATA_PATH = './_data/rpl/'\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2base64(s):\n",
    "    return base64.b64encode(s.encode('utf-8')).decode('ascii')\n",
    "def get_token_data(log_url, creds, data):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/x-www-form-urlencoded',\n",
    "        'Authorization': 'Basic {}'.format(string2base64(creds))\n",
    "    }\n",
    "    r = requests.post(\n",
    "        log_url, \n",
    "        headers=headers,\n",
    "        data=data\n",
    "    )\n",
    "    try:\n",
    "        token_data = r.json()\n",
    "    except:\n",
    "        print(r.text, '\\n')\n",
    "        token_data = {}\n",
    "    return token_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_url = 'https://rfpl.sportand.me/authserver/oauth/token'\n",
    "creds = 'rfsconsumer:K0Ka3jnfsd9afsd9llaD5gkss'\n",
    "data = 'grant_type=client_credentials'\n",
    "token_data = get_token_data(log_url, creds, data)\n",
    "print(token_data)\n",
    "token = token_data['access_token']\n",
    "print('token: ', token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url, token, limit=100, offset=0, max_counts=5, time_sleep=5):\n",
    "    offset = offset\n",
    "    data = []\n",
    "    count = 0\n",
    "    while True:\n",
    "        print('url: ', url, ' | processing offset from: ', offset)\n",
    "        params = {'access_token': token, 'limit': limit, 'offset': offset}\n",
    "        r = requests.get(url, params=params)\n",
    "        if r.json()['success']:\n",
    "            if not r.json()['errors']:\n",
    "                if (len(r.json()['data']) == 0):\n",
    "                    break\n",
    "                elif isinstance(r.json()['data'], dict):\n",
    "                    data = r.json()['data']\n",
    "                    break\n",
    "                else:\n",
    "                    data.extend(r.json()['data'])\n",
    "                    offset += len(r.json()['data'])\n",
    "            else:\n",
    "                print('errors: ', r.json()['errors'])\n",
    "                count += 1\n",
    "                sleep(time_sleep)\n",
    "        else:\n",
    "            print('success: ', r.json()['success'], ' | errors: ', r.json()['errors'])\n",
    "            count += 1\n",
    "            sleep(time_sleep)\n",
    "        if count >= max_counts:\n",
    "            break\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_person_dict = {\n",
    "    'clubofficialperson_data': 'https://rfpl.sportand.me/api/clubofficialperson',\n",
    "    'officialperson_data': 'https://rfpl.sportand.me/api/officialperson',\n",
    "    'person_data': 'https://rfpl.sportand.me/api/person',\n",
    "    'player_data': 'https://rfpl.sportand.me/api/player',\n",
    "    'teamrepresentative_data': 'https://rfpl.sportand.me/api/teamrepresentative'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, url in by_person_dict.items():\n",
    "    print('processing: ', name)\n",
    "    data = get_data(url, token, limit=1000, offset=0, max_counts=MAX_COUNTS, time_sleep=TIME_SLEEP)\n",
    "    file_name = '{}{}.txt'.format(DATA_PATH, name)\n",
    "    with open(file_name, 'w') as file:\n",
    "        json.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By clubs and teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_clubs_teams_dict = {\n",
    "    'clubs': 'https://rfpl.sportand.me/api/club',\n",
    "    'teams': 'https://rfpl.sportand.me/api/team'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, url in by_clubs_teams_dict.items():\n",
    "    print('processing: ', name)\n",
    "    data = get_data(url, token, limit=1000, offset=0, max_counts=MAX_COUNTS, time_sleep=TIME_SLEEP)\n",
    "    file_name = '{}{}.txt'.format(DATA_PATH, name)\n",
    "    with open(file_name, 'w') as file:\n",
    "        json.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By tournaments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_tournaments_dict = {\n",
    "    'competitions': [\n",
    "        'https://rfpl.sportand.me/api/competition', \n",
    "        'tournaments' #Идентификатор соревнования\n",
    "    ], \n",
    "    'seasons': [\n",
    "        'https://rfpl.sportand.me/api/season', \n",
    "        'applications', #Идентификатор сезона\n",
    "        'tournaments' #Идентификатор сезона\n",
    "    ], \n",
    "    'tournaments': [\n",
    "        'https://rfpl.sportand.me/api/tournament', \n",
    "        'matches', #Идентификатор турнира\n",
    "        'teams', #Идентификатор турнира\n",
    "        'stages', #Идентификатор турнира\n",
    "    ] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, url_list in by_tournaments_dict.items():\n",
    "    print('processing: ', name)\n",
    "    data = get_data(url_list[0], token, limit=1000, offset=0, max_counts=MAX_COUNTS, time_sleep=TIME_SLEEP)\n",
    "    file_name = '{}{}.txt'.format(DATA_PATH, name)\n",
    "    with open(file_name, 'w') as file:\n",
    "        json.dump(data, file)\n",
    "    dir_name = '{}/{}'.format(DATA_PATH, name)\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    for item in data:\n",
    "        id_item = item['id']\n",
    "        for num_url_id in range(1, len(url_list)):\n",
    "            print('processing: ', name, ' | sub: ', url_list[num_url_id], 'id: ', id_item)\n",
    "            id_url = '{}/{}/{}'.format(url_list[0], id_item, url_list[num_url_id])\n",
    "            id_data = get_data(id_url, token, limit=1000, offset=0, max_counts=MAX_COUNTS, time_sleep=TIME_SLEEP)\n",
    "            file_name = '{}/id{}_{}.txt'.format(dir_name, id_item, url_list[num_url_id])\n",
    "            with open(file_name, 'w') as file:\n",
    "                json.dump(id_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_tour_list = []\n",
    "dir_name = '{}/tournaments'.format(DATA_PATH, name)\n",
    "for file_name in [x for x in os.listdir(dir_name) if 'stages' in x]:\n",
    "    with open('{}/{}'.format(dir_name, file_name), 'r') as file:\n",
    "        data = json.load(file)\n",
    "    id_tour_list.extend([x['id'] for x in data])\n",
    "print('total ids tours: ', len(id_tour_list), ' | unique ids: ', len(set(id_tour_list)))\n",
    "dir_name = '{}/{}'.format(DATA_PATH, 'tours')\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "url_tours = 'https://rfpl.sportand.me/api/tournamentstage'\n",
    "for id_tour in id_tour_list:\n",
    "    id_url = '{}/{}'.format(url_tours, id_tour)\n",
    "    id_data = get_data(id_url, token, limit=1000, offset=0, max_counts=MAX_COUNTS, time_sleep=TIME_SLEEP)\n",
    "    file_name = '{}/id{}.txt'.format(dir_name, id_tour, url_list[num_url_id])\n",
    "    with open(file_name, 'w') as file:\n",
    "        json.dump(id_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_applications_dict = {\n",
    "    'applications': [\n",
    "        'https://rfpl.sportand.me/api/application', \n",
    "        'coaches', #Идентификатор заявки клуба\n",
    "        'heads', #Идентификатор заявки клуба\n",
    "        'players' #Идентификатор заявки клуба\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, url_list in by_applications_dict.items():\n",
    "    print('processing: ', name)\n",
    "    data = get_data(url_list[0], token, limit=1000, offset=0, max_counts=MAX_COUNTS, time_sleep=TIME_SLEEP)\n",
    "    file_name = '{}{}.txt'.format(DATA_PATH, name)\n",
    "    with open(file_name, 'w') as file:\n",
    "        json.dump(data, file)\n",
    "    dir_name = '{}/{}'.format(DATA_PATH, name)\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    for item in data:\n",
    "        id_item = item['id']\n",
    "        for num_url_id in range(1, len(url_list)):\n",
    "            print('processing: ', name, ' | sub: ', url_list[num_url_id], 'id: ', id_item)\n",
    "            id_url = '{}/{}/{}'.format(url_list[0], id_item, url_list[num_url_id])\n",
    "            id_data = get_data(id_url, token, limit=1000, offset=0, max_counts=MAX_COUNTS, time_sleep=TIME_SLEEP)\n",
    "            file_name = '{}/id{}_{}.txt'.format(dir_name, id_item, url_list[num_url_id])\n",
    "            with open(file_name, 'w') as file:\n",
    "                json.dump(id_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_matches_list = []\n",
    "dir_name = '{}/tournaments'.format(DATA_PATH, name)\n",
    "for file_name in [x for x in os.listdir(dir_name) if 'matches' in x]:\n",
    "    with open('{}/{}'.format(dir_name, file_name), 'r') as file:\n",
    "        data = json.load(file)\n",
    "    id_matches_list.extend([x['id'] for x in data])\n",
    "print('total ids matches: ', len(id_matches_list), ' | unique ids: ', len(set(id_matches_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_name = '{}/{}'.format(DATA_PATH, 'matches')\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "url_matches = 'https://rfpl.sportand.me/api/match'\n",
    "start_index = len(os.listdir(dir_name))\n",
    "print('start from: ', start_index)\n",
    "for id_match in id_matches_list[start_index:]:\n",
    "    id_url = '{}/{}'.format(url_matches, id_match)\n",
    "    id_data = get_data(id_url, token, limit=1000, offset=0, max_counts=MAX_COUNTS, time_sleep=TIME_SLEEP)\n",
    "    file_name = '{}/id{}.txt'.format(dir_name, id_match)\n",
    "    with open(file_name, 'w') as file:\n",
    "        json.dump(id_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_dictionaries_dict = {\n",
    "    'countries': 'https://rfpl.sportand.me/api/country',\n",
    "    'redcardtypes': 'https://rfpl.sportand.me/api/redcardtype',\n",
    "    'refereecategories': 'https://rfpl.sportand.me/api/refereecategory',\n",
    "    'regions': 'https://rfpl.sportand.me/api/region',\n",
    "    'stadiums': 'https://rfpl.sportand.me/api/stadium',\n",
    "    'yellowcardtypes': 'https://rfpl.sportand.me/api/yellowcardtype'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, url in by_dictionaries_dict.items():\n",
    "    print('processing: ', name)\n",
    "    data = get_data(url, token, limit=1000, offset=0, max_counts=MAX_COUNTS, time_sleep=TIME_SLEEP)\n",
    "    file_name = '{}{}.txt'.format(DATA_PATH, name)\n",
    "    with open(file_name, 'w') as file:\n",
    "        json.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = {\n",
    "    'history': 'https://rfpl.sportand.me/api/history'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, url in history_dict.items():\n",
    "    print('processing: ', name)\n",
    "    data = get_data(url, token, limit=1000, offset=0, max_counts=MAX_COUNTS, time_sleep=TIME_SLEEP)\n",
    "    file_name = '{}{}.txt'.format(DATA_PATH, name)\n",
    "    with open(file_name, 'w') as file:\n",
    "        json.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
